<div align="center"><img src="https://docs.nvidia.com/cuda/_static/Logo_and_CUDA.png" alt="CUDA" height="80"></div> 

Important links: 1 (https://github.com/rkinas/cuda-learning) 2(https://github.com/hkproj/100-days-of-gpu/tree/main)

## LEARNING PATH - From Basics to Advanced CUDA Programming

This structured learning path guides you through the essential steps required to become proficient in CUDA programming, starting from foundational programming knowledge to advanced GPU computing concepts. The path emphasizes building a strong base in programming, understanding data structures, mastering C++, and diving into GPU architecture and CUDA-specific optimizations. Resources include both English and Polish materials, offering flexibility based on language preference.

1. **C Programming**:  
   Begin with C programming if you are unfamiliar with it. A solid understanding of C is mandatory before transitioning to C++ programming.  
   - [The C Programming Language (ANSI C) by Brian Kernighan and Dennis Ritchie](https://www.amazon.com/Programming-Language-2nd-Brian-Kernighan/dp/0131103628)
   - Practicing C programming [GPT-2 from Scratch in C - Part 1](https://youtu.be/d1LNUvkRMEg?si=j265w0Hoje-rxfrN) and [GPT-2 from Scratch in C - Part 2](https://youtu.be/j-kMKBQ1vkw?si=iGtmMMLi5DfMlvXf)
   - ðŸ‡µðŸ‡± [Podstawy programowania. JÄ™zyk C](https://www.udemy.com/course/podstawy-programowania-jezyk-c)  
   - ðŸ‡µðŸ‡± [Zaawansowane programowanie w jÄ™zyku C](https://www.udemy.com/course/zaawansowane-programowanie-w-jezyku-c/)  

2. **Data Structures**:  
   Learn essential data structures and algorithms, a prerequisite for effective problem-solving and programming.  
   - ðŸŽ¥[C++ Data Structures & Algorithms + LEETCODE Exercises](https://www.udemy.com/course/data-structures-algorithms-cpp/)  
   - [Data Structures and Algorithms](https://github.com/sachuverma/DataStructures-Algorithms) -> [Leetcode](https://leetcode.com/)
   - ðŸ“– Introduction to Algorithms, fourth edition by Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest and Clifford Stein
   - ðŸ‡µðŸ‡± ðŸ“– *Algorytmy, struktury danych i techniki programowania* by PaweÅ‚ WrÃ³blewski  
   - ðŸ‡µðŸ‡± ðŸ“– *C++. Algorytmy i struktury danych* by Adam Drozdek  

3. **C++ Programming**:  
   Master C++ programming as it serves as a foundation for CUDA development.  
   - ðŸŽ¥ [Beginning C++ Programming - From Beginner to Beyond](https://www.udemy.com/course/beginning-c-plus-plus-programming/)  
   - ðŸŽ¥ [Back to Basics](https://www.youtube.com/playlist?list=PLHTh1InhhwT4TJaHBVWzvBOYhp27UO7mI)
   - ðŸ“–[Modern C++ Tutorial: C++11/14/17/20 On the Fly](https://github.com/changkun/modern-cpp-tutorial)
   - ðŸ‡µðŸ‡± ðŸŽ¥ [C++ od Podstaw do Eksperta](https://www.udemy.com/course/c-od-podstaw-do-eksperta/)
   - ðŸ‡µðŸ‡± ðŸ“– [Opus magnum C++11](https://www.ifj.edu.pl/private/grebosz/opus.html)
   - ðŸ‡µðŸ‡± ðŸ“– *JÄ™zyk C++ Kompendium Wiedzy* by Bjarne Stroustrup

4. **Parallel Computing**:  
   Understand the basics of parallel computing and modern hardware architectures.  
   - ðŸŽ¥ [GPU Computing](https://www.youtube.com/playlist?list=PLRRuQYjFhpmubuwx-w8X964ofVkW1T8O4)  
   - [Algorithms for Modern Hardware](https://en.algorithmica.org/hpc/)
   - ðŸŽ¥ [Learn Multithreading with Modern C++](https://www.udemy.com/course/learn-modern-cplusplus-concurrency/)
   - [Stanford CS149 - Parallel computing](https://gfxcourses.stanford.edu/cs149/fall24)
   - ðŸ‡µðŸ‡± ðŸŽ¥ [Programowanie rÃ³wnolegle z wykorzystaniem wspÃ³Å‚czesnych architektur komputerowych z pamiÄ™ciÄ… wspÃ³Å‚dzielonÄ…](https://icis.pcz.pl/~khalbiniak/OpenMP/)  


5. **CUDA Programming**:  
   Dive into CUDA, learning GPU programming techniques, optimizations, and advanced performance tuning.  
   - [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf) 
   - ðŸŽ¥ [CUDA Parallel Programming on NVIDIA GPUs - HW and SW](https://www.udemy.com/course/cuda-parallel-programming-on-nvidia-gpus-hw-and-sw/?couponCode=KEEPLEARNING)  
   - [CUDA Samples](https://github.com/NVIDIA/cuda-samples)  
   - ðŸŽ¥ [CUDA Programming Course â€“ High-Performance Computing with GPUs](https://www.youtube.com/watch?v=86FAWCzIe_4)  
   - ðŸ“– *Programming Massively Parallel Processors* by  David B. Kirk, Wen-mei W. Hwu
   - [Programming in Parallel with CUDA - programmers guide](https://www.perlego.com/book/4229601/programming-in-parallel-with-cuda-a-practical-guide-pdf)
   - ðŸŽ¥ [CUDA training series](https://www.youtube.com/playlist?list=PL6RdenZrxrw-zNX7uuGppWETdxt_JxdMj)
   - ðŸŽ¥ [GPU Programming](https://www.youtube.com/watch?v=c8mQYGbT310&list=PL5XwKDZZlwaY7t0M5OLprpkJUIrF8Lc9j)
   - ðŸ‡µðŸ‡± [CUDA - Tomasz Jasiukiewicz](https://www.youtube.com/watch?v=LNA_CYZbDtY&list=PLoHYlZuJfhOGHKKEwt4tn8KUTJvbbtRL_)
 

6. **Triton, ThunderKittens, Tile-Lang**:  
   Explore the Triton, ThunderKittens, Tile-Lang frameworks for GPU programming with efficient performance.  
   - [Remek's Triton Repo](https://github.com/rkinas/triton-resources)
   - [ThunderKittens Framework](https://github.com/HazyResearch/ThunderKittens) and [startet pack](https://docs.google.com/document/d/15-Zvf6e0NLX1si4ml4sUOWCDlXNMtOWKiuo6CKZMEYA/edit?usp=sharing)
   - [Tile Language (tile-lang) is a concise domain-specific language designed to streamline the development of high-performance GPU/CPU kernels (e.g., GEMM, Dequant GEMM, FlashAttention, LinearAttention)](https://github.com/tile-ai/tilelang) 

7. **GPU Architecture and Glossary**:  
   Familiarize yourself with GPU architecture and terminology to deepen your understanding of hardware capabilities.  
   - [GPU Glossary](https://modal.com/gpu-glossary)
  
8. **100Days of CUDA programming**:
   - [100Days of CUDA programming - list of challnages (a lot of repos as a source of challange inspirations)](https://github.com/hkproj/100-days-of-gpu)
   - [CUDA 120 days challange](https://github.com/AdepojuJeremy/Cuda-120-Days-Challenge/tree/main?tab=readme-ov-file)
   - [Learning GPU Programming 30 days plan](https://antaripasaha.notion.site/Learning-GPU-Programming-30-days-plan-1885314a563980be95a6e9fd43c4c217)

This comprehensive learning path equips you with the skills needed to progress from foundational programming to advanced CUDA development, paving the way for a career in GPU-accelerated computing.

## Matmul ##
This section focuses on understanding the fundamentals and optimization of matrix multiplication (Matmul), a cornerstone operation in CUDA programming and high-performance computing (HPC). The provided resources cover both CPU implementations and GPU optimizations, including the use of Tensor Cores on architectures like Ampere and Ada. These materials are essential for building a strong foundation in writing optimized CUDA code.

- **Matmul theory
   - [Matrix Calculus (for Machine Learning and Beyond)](https://arxiv.org/abs/2501.14787) 

- **Matmul on CPU**: Analysis of efficient matrix multiplication implementations on CPUs, with detailed examples of optimizations:
  - [Beating OpenBLAS in FP32 Matrix Multiplication: A Full Walkthrough](https://salykova.github.io/matmul-cpu)
  - [Fast Multidimensional Matrix Multiplication on CPU from Scratch](https://siboehm.com/articles/22/Fast-MMM-on-CPU)
  - [Optimizing Matrix Multiplication](https://coffeebeforearch.github.io/2020/06/23/mmul.html)
  - [Matrix Multiplication on CPU](https://marek.ai/matrix-multiplication-on-cpu.html)
- **CUDA Matmul Optimizations**:
   - [Beating cuBLAS in Single-Precision General Matrix Multiplication](https://salykova.github.io/sgemm-gpu)
   - GPU H100: [Outperforming cuBLAS on H100: a Worklog](https://cudaforfun.substack.com/p/outperforming-cublas-on-h100-a-worklog)
   - Ada Architecture: [Implementing a fast Tensor Core matmul on the Ada Architecture](https://www.spatters.ca/mma-matmul)
  - Ampere Architecture: [How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog](https://siboehm.com/articles/22/CUDA-MMM)
  - [CUDA Matrix Multiplication Optimization](https://leimao.github.io/article/CUDA-Matrix-Multiplication-Optimization/)
  - [Learning CUDA by optimizing matrix-vector multiplication (SGEMV) for cuBLAS-like performance - A worklog](https://maharshi.bearblog.dev/optimizing-sgemv-cuda/)
  - [Matrix Multiplication with CUDA â€” A basic introduction to the CUDA programming model](http://www.shodor.org/media/content/petascale/materials/UPModules/matrixMultiplication/moduleDocument.pdf)
  - [Inconsistency in GEMM Performance](https://yywangcs.notion.site/Inconsistency-in-GEMM-Performance-16efc9f5d80580838090dded05493014)
  - [Fastest GPU kernels, written from scratch.](https://github.com/pranjalssh/fast.cu)
  - [GPU Mode - Lecture 45: Outperforming cuBLAS on H100](https://www.youtube.com/watch?v=ErTmTCRP1_U)
  - [Insanely Fast H100 Matrix Multiplication](https://github.com/ademeure/hopperian_tensor)
- **Theory and Basics**:
  - [CUDA Matrix Multiplication](https://leimao.github.io/blog/CUDA-Matrix-Multiplication/)
  - [Matrix Multiplication Implementation Using NVIDIA Tensor Core](https://leimao.github.io/blog/NVIDIA-Tensor-Core-Programming/)
  - [Matrix Multiplication Background User's Guide](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html)
  - [Memory Coalescing and Tiled Matrix Multiplication](https://0mean1sigma.com/chapter-4-memory-coalescing-and-tiled-matrix-multiplication/)

These resources provide a comprehensive theoretical and practical foundation in matrix multiplication, enabling you to master CUDA learning and better understand algorithm optimization in GPU environments.

## Softmax ##
- [Learning CUDA by optimizing softmax: A worklog](https://maharshi.bearblog.dev/optimizing-softmax-cuda/)
- [How to write a fast Softmax CUDA kernel?](https://github.com/facebookincubator/AITemplate/wiki/How-to-write-a-fast-Softmax-CUDA-kernel%3F)
- [How to Implement an Efficient Softmax CUDA Kernelâ€” OneFlow Performance Optimization](https://oneflow2020.medium.com/how-to-implement-an-efficient-softmax-cuda-kernel-oneflow-performance-optimization-sharing-405ad56e9031)
- [Optimizing Softmax on CUDA: A Dive into High-Performance Kernels](https://1y33.github.io/blog/softmax_optimization/)

## Sort ##
- [Performance Optimization of torch.sort on GPU](https://yywangcs.notion.site/Performance-Optimization-of-torch-sort-on-GPU-192fc9f5d8058018a1bec1efa35da3f9)

## GPU programming resources
### Description of the Section: GPU Programming Resources

This section provides a curated collection of resources for learning, exploring, and mastering GPU programming. It covers various aspects of GPU development, including community engagement, architectural insights, tutorials, example implementations, benchmarking, and advanced tools. These resources cater to developers at different expertise levels, offering a pathway to build and optimize high-performance GPU applications.

---

#### **1. Communities**  
Engage with fellow developers and experts in the field of GPU programming:  
- [NVIDIA CUDA Forum](https://forums.developer.nvidia.com/c/accelerated-computing/cuda/206)
- [CUDA-MODE](https://discord.gg/gpumode)

---

#### **2. GPU Architectures**  
Understand the underlying architecture of GPUs to optimize code efficiently:  
- [Ampere Architecture](https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/)  
- [Ada Architecture](https://images.nvidia.com/aem-dam/en-zz/Solutions/technologies/NVIDIA-ADA-GPU-PROVIZ-Architecture-Whitepaper_1.1.pdf)  
- [Hopper Architecture](https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/)  
- [Grace-Hopper Architecture](https://developer.nvidia.com/blog/nvidia-grace-hopper-superchip-architecture-in-depth/)  
- [GPUs Go Brrr](https://hazyresearch.stanford.edu/blog/2024-05-12-tk)

---

#### **3. Tutorials**  
Learn the practical aspects of GPU programming with these tutorials:  
- [GPU Puzzles - to solve](https://github.com/srush/gpu-puzzles) -> [Solved](https://github.com/isamu-isozaki/GPU-Puzzles-answers/blob/main/GPU_puzzlers.ipynb) 
- [Accurate Timing of CUDA Kernels in PyTorch](https://www.speechmatics.com/company/articles-and-news/timing-operations-in-pytorch)

---

#### **4. Courses**  
Comprehensive courses to deepen your GPU programming skills:  
- [Parallel Computing Using CUDA-C](https://github.com/CisMine/Parallel-Computing-Cuda-C?tab=readme-ov-file)  
- [CUDA Course](https://github.com/Infatoshi/cuda-course)  
- [CUDA Tutorial Code Samples](https://github.com/CUDA-Tutorial/CodeSamples)  
- [CUDA Tutorial](https://cuda-tutorial.github.io/)
- [NVIDIA will present a 13-part CUDA training series](https://www.olcf.ornl.gov/cuda-training-series/)

---

#### **5. Videos**  
Explore video tutorials and insights on GPU programming:  
- [Programming Massively Parallel Processors](https://www.youtube.com/playlist?list=PLRRuQYjFhpmubuwx-w8X964ofVkW1T8O4)  
- [Simon Oz - GPU Programming](https://www.youtube.com/playlist?list=PL5XwKDZZlwaY7t0M5OLprpkJUIrF8Lc9j)  
- [CUDA Programming](https://www.youtube.com/playlist?list=PLU0zjpa44nPXddA_hWV1U8oO7AevFgXnT)  
- [George Hotz Archive](https://www.youtube.com/@geohotarchive/videos)

---

#### **6. Example Implementations**  
Explore real-world examples and implementations:  
- [llm.c](https://github.com/karpathy/llm.c)  
- [Fast LLM Inference From Scratch](https://andrewkchan.dev/posts/yalm.html)  
- [MNIST CUDA](https://github.com/Infatoshi/mnist-cuda)  
- [Softmax](https://github.com/SzymonOzog/FastSoftmax)  
- [YALM: LLM Inference in C++/CUDA](https://github.com/andrewkchan/yalm/tree/main)  
- [llm.cpp: Training and Inference](https://github.com/karpathy/llm.c/tree/master)  
- [CUTLASS Tutorial: Fast Matrix Multiplication with WGMMA on Hopper GPUs](https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/)
- [Many many CUDA kernels from "100 days of CUDA challange"](https://github.com/prateekshukla1108/kernels-project-popcorn)

---

#### **7. Kernel Leaderboard**  
Track performance and benchmarks of GPU kernels:  
- [Kernel Leaderboard](https://scalingintelligence.stanford.edu/KernelBenchLeaderboard/)  
- [KernelBench Blog](https://scalingintelligence.stanford.edu/blogs/kernelbench/)

---

#### **8. Benchmarking**  
Compare GPU performance and analyze benchmarks:  
- [MI300X vs H100 vs H200 Training Benchmarks](https://semianalysis.com/2024/12/22/mi300x-vs-h100-vs-h200-benchmark-part-1-training/)  
- [Forecasting GPU Performance](https://arxiv.org/pdf/2407.13853)  
- [Benchmarking Nvidia Hopper GPU Architecture](https://arxiv.org/pdf/2402.13499v1)  
- [Maximum Achievable Matmul FLOPS Finder](https://github.com/stas00/ml-engineering/tree/master/compute/accelerator/benchmarks)

---

#### **9. Patterns and Algorithms**  
Understand key HPC algorithms like matrix multiplication:  
- [HPC Matmul Algorithms](https://en.algorithmica.org/hpc/algorithms/matmul/)

---

#### **10. Articles**  
Insights into GPU performance and its nuances:
- [Introduction to CUDA Programming for Python Developers](https://www.pyspur.dev/blog/introduction_cuda_programming)
- [The GPU is Not Always Faster](https://cowfreedom.de/#dot_product/introduction/)
- [Series of articles explaining GPU programming](https://giahuy04.medium.com/) -> [Demystifying CPUs and GPUs: What You Need to Know](https://giahuy04.medium.com/demystifying-cpus-and-gpus-what-you-need-to-know-5bb423be726b), [How the way a computer works](https://giahuy04.medium.com/how-the-way-a-computer-works-a8b8d253da21), [Terminology in parallel programming](https://giahuy04.medium.com/terminology-in-parallel-programming-a2c4d7d062cf), [Hello world Cuda-C](https://giahuy04.medium.com/hello-world-cuda-c-ddfd7a8aeb8c), [The operational mechanism of CPU-GPU](https://giahuy04.medium.com/the-operational-mechanism-of-cpu-gpu-acf6e7723b2b), [Memory Types in GPU](https://ai.gopubby.com/memory-types-in-gpu-6373b7a0ca47), [Using GPU memory](https://giahuy04.medium.com/using-gpu-memory-a75e0fabe3f0), [Synchronization and Asynchronization](https://giahuy04.medium.com/synchronization-and-asynchronization-0024fe9e7329), [Unified memory](https://giahuy04.medium.com/unified-memory-81bb7c0f0270), [Pinned memory](https://giahuy04.medium.com/pinned-memory-5d408b72241d), [Streaming](https://giahuy04.medium.com/streaming-0fbc7b1a5fff), [Data Hazard](https://giahuy04.medium.com/data-hazard-cd0e9e50cce2), [Warp Scheduler](https://giahuy04.medium.com/warp-scheduler-f7318ef17920), [Global Memory Coalescing](https://giahuy04.medium.com/global-memory-coalescing-37a6f9d7e314), [Atomic Function](https://giahuy04.medium.com/atomic-function-9f5c5a414181),[Bandwidth â€” Throughput â€” Latency](https://giahuy04.medium.com/bandwidth-throughput-latency-935ada83d1ae),[Occupancy in GPU Part 1](https://giahuy04.medium.com/occupancy-in-gpu-ddb0b1f16b20), [Occupancy in GPU Part 2](https://giahuy04.medium.com/occupancy-part-2-7a5c671a1fb0)
- [Recreating PyTorch from Scratch - with GPU Support and Automatic Differentiation](https://towardsdatascience.com/recreating-pytorch-from-scratch-with-gpu-support-and-automatic-differentiation-8f565122a3cc)
- [CUDA](https://stevengong.co/notes/CUDA)
- [A minimal GPU implementation in Verilog optimized for learning about how GPUs work from the ground up](https://github.com/adam-maj/tiny-gpu)
- [Performance Optimization of Embedding Computation on GPU Part 1: GPU Occupancy Optimization](https://yywangcs.notion.site/Performance-Optimization-of-Embedding-Computation-on-GPU-Part-1-GPU-Occupancy-Optimization-178fc9f5d805800e91b6d4490afcc665)

---

#### **11. Papers**  
Explore state-of-the-art research in GPU programming:  
- [The Case for Co-Designing Model Architectures with Hardware](https://arxiv.org/pdf/2401.14489)

---

#### **12. Tools**  
Useful tools for tuning and analyzing GPU performance:  
- [NVIDIA Nsight Compute](https://developer.nvidia.com/nsight-compute)
- [CUDA Profiler User Guide](https://docs.nvidia.com/cuda/profiler-users-guide/contents.html)
- [Kernel Tuner](https://kerneltuner.github.io/kernel_tuner/stable/contents.html)
- [LeetGPU - Only platform to write and run CUDA code. Without a GPU. For Free.](https://leetgpu.com/)

### **13. CUTLAS**
- [CUTLASS Tutorial: Persistent Kernels and Stream-K](https://research.colfax-intl.com/cutlass-tutorial-persistent-kernels-and-stream-k/)
- [CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining](https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/)
- [CUTLASS Tutorial: Fast Matrix-Multiplication with WGMMA on NVIDIAÂ® Hopperâ„¢ GPUs](https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/)
- [CUTLASS Tutorial: Mastering the NVIDIAÂ® Tensor Memory Accelerator (TMA)](https://research.colfax-intl.com/tutorial-hopper-tma/)
- [Tutorial: Matrix Transpose in CUTLASS](https://research.colfax-intl.com/tutorial-matrix-transpose-in-cutlass/)
---

### **14. Other**
- [The Rust CUDA Project](https://github.com/rust-gpu/rust-cuda)

### **15. CUDA kernel generators**
- [The AI CUDA Engineer: Agentic CUDA Kernel Discovery, Optimization and Composition](https://sakana.ai/ai-cuda-engineer/)
- [Automating GPU Kernel Generation with DeepSeek-R1 and Inference Time Scaling](https://developer.nvidia.com/blog/automating-gpu-kernel-generation-with-deepseek-r1-and-inference-time-scaling/)

This resource list offers a comprehensive set of tools, tutorials, and materials to help developers advance their GPU programming expertise, from beginner to professional levels.

## Parallel computing
- [Programming Parallel Computers](https://ppc.cs.aalto.fi/)

